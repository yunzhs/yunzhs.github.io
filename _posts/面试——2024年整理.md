#### collections的相关子类整理

**list：**[ArrayList]  [LinkedList]  [Vector]   

**list的主要特点：**
都是一个有序容器，保证了每个元素的插入顺序
可以插入null元素

**ArrayList和LinkedList的区别**
a基于动态数组，l基于链表
因此随机访问时（get，set），a是占优的，因为l还有移动指针
而对于新增或删除数据，l是占优的，因为a要移动数据，l只需要指针重定向

**Vector和ArrayList的区别**
Vector是线程安全的，所有性能上必然会差点
当容量超过原定大小时（a的默认大小为10），a会按50%进行扩容，v则会100%扩容

**set：**[HashSet]  [LinkedHashSet]  [TreeSet]   

**set的主要特点：**
不需要重复对象
无序容器
只允许一个null

**HashSet和LinkedHashSet的区别**
l继承于h，h是基于hashmap实现的，集合元素实际上是由map的key来保存的，而对应的value则是PRESENT,它是一个默认的OBJECT对象
l能够按照添加的顺序进行遍历，只能从头到尾，不能指定位置
h的顺序则是数据的hash值来确定的

TreeSet则主要是内部维护了compare方法，来保准顺序

**map：**[HashMap]  [LinkedHashMap]  [TreeMap]   [concurrentHashMap]

**LinkedHashMap**：
LinkedHashMap同LinkedHashSet，都维护了一个双向链表，它能维护链表的插入顺序。
LinkedHashMap同样能记录访问顺序
由于维护了顺序，所以他的占用是要比hashmap高


### kafka高可用模式

集群分为leader和broker，会有副本机制，消息partition会存在多个broker里，并存有副本，这种情况下，如果一个宕机了，数据也不会丢失。

### 消息队列重复消费

一条消息如果在消费完了返回时，服务器宕机重启了，那就不会被标记为已消费，就会再去消费

方案，根据实际情况保证幂等，先看是否是天然幂等，如果不是则考虑维护唯一消息id


### 消息队列丢了数据处理

##### Rabbit 服务端丢了数据
启用持久化策略，把队列和消息都设置为持久化
##### Rabbit消费端丢了数据
采用ack机制，消费完了再给消费队列确认一下


### RocketMQ怎样保证消息的顺序性

比如同步一个增删改的操作，通过消息队列，保证其顺序执行

两个必要条件：
1、单一生产者
2、消息串行发送

方案：
生产者顺序性
```
SendResult sendResult = producer.send(msg, new MessageQueueSelector() {  
@Override  
public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {  
Integer id = (Integer) arg;  
int index = id % mqs.size();  
return mqs.get(index);  
}  
//orderId就是arg
}, orderId);

```
消费者顺序性
主要是保证并发消息时保证顺序,一个队列绑定一个消费线程
实现MessageListenerOrderly接口
```
consumer.registerMessageListener(new MessageListenerOrderly() {  
AtomicLong consumeTimes = new AtomicLong(0);  
@Override  
public ConsumeOrderlyStatus consumeMessage(List<MessageExt> msgs, ConsumeOrderlyContext context) {  
System.out.printf("%s Receive New Messages: %s %n", Thread.currentThread().getName(), msgs);  
this.consumeTimes.incrementAndGet();  
//这个取余是真没看懂
if ((this.consumeTimes.get() % 2) == 0) {  
return ConsumeOrderlyStatus.SUCCESS;  
} else if ((this.consumeTimes.get() % 5) == 0) {  
context.setSuspendCurrentQueueTimeMillis(3000);  
return ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT;  
}  
return ConsumeOrderlyStatus.SUCCESS;  
}  
});
```


**RocketMQ还支持严格顺序，即放弃可用性（速度）
通过配置对应的参数**

### RocketMQ 延迟消息
message.setDelayTimeLevel(3);
可以设置延迟等级来设置延迟消息

### RocketMQ事务消费（可靠消息最终一致性方案）
1、  生产者将半事务消息发送至 `RocketMQ Broker`。
2、`RocketMQ Broker` 将消息持久化成功之后，向生产者返回 Ack 确认消息已经发送成功，此时消息暂不能投递，为半事务消息。
3、 生产者开始执行本地事务逻辑。
4、生产者根据本地事务执行结果向服务端提交二次确认结果（Commit或是Rollback），服务端收到确认结果后处理逻辑如下：
-   二次确认结果为Commit：服务端将半事务消息标记为可投递，并投递给消费者。
-   二次确认结果为Rollback：服务端将回滚事务，不会将半事务消息投递给消费者。
5、在断网或者是生产者应用重启的特殊情况下，若服务端未收到发送者提交的二次确认结果，或服务端收到的二次确认结果为Unknown未知状态，经过固定时间后，服务端将对消息生产者即生产者集群中任一生产者实例发起消息回查。 
6.需要注意的是，服务端仅仅会按照参数尝试指定次数，超过次数后事务会强制回滚，因此未决事务的回查时效性非常关键，需要按照业务的实际风险来设置 

### 大量消息挤压如何解决？

出现挤压主要是消费者的问题，这里的解决思路：

1、先修复consumer的问题，恢复其消费速度，再将原有consumer重启
2、新建一个topic，partition是原来的十倍，queue也是十倍
3、新写一个consumer，去将原topic的消息分发到新topic上
4、部署十倍的consumer去消费新topic上的数据
5、恢复成原有架构

这里之所以不使用直接增加十倍机器去处理，而是新建topic，我的理解是减少入侵，不对原有topic做改变，方便复原。

### Redis五种基础数据类型，底层实现
String：简单动态字符串
List：双向链表、压缩列表
Hash：压缩列表、哈希表
Sorted Set：压缩列表、跳表（随机化，能够进行二分查找）
Set：哈希表、整数数组

### Redis的list，set应用

list是有序列表，可以用其range命令，做微博评论那样的功能
也可以做异步队列，用push和pop

set主要用做去重，如查看两个人共同的粉丝，就可以直接把两人的粉丝放一个set里去重

zset可以做排名功能

### LRU(最近最少使用)的java简单实现
```
public class LRUCache<K, V> extends LinkedHashMap<K, V> {
    private int capacity;

    /**
     * 传递进来最多能缓存多少数据
     *
     * @param capacity 缓存大小
     */
    public LRUCache(int capacity) {
        super(capacity, 0.75f, true);
        this.capacity = capacity;
    }

    /**
     * 如果map中的数据量大于设定的最大容量，返回true，再新加入对象时删除最老的数据
     *
     * @param eldest 最老的数据项
     * @return true则移除最老的数据
     */
    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        // 当 map中的数据量大于指定的缓存个数的时候，自动移除最老的数据
        return size() > capacity;
    }
}
```






### 双写数据库迁移方案
最简单的就是停机导数据库，但是基本不用了，现在都是双写

就是新库老库，同时进行增删改，但读还是读老库，与此同时，进行老库数据导入到新库的操作，直至导入完毕，进行多次对比，无误后进行切库。

### 读写分离的概念

数据库分为主库和从库，主库负责写，从库负责读

从库通过读主库的binlog日志，串行执行

如果并发过高时，从库可能会比较慢，这时候就需要去解决
一般通过主库分库的方式，主库进行拆分，实现分流

### 如何设计高并发系统？看这六点

- 系统拆分
- 缓存
- MQ
- 分库分表
- 读写分离
- ES


### 分布式事务

主要分为四种：
XA
TCC
saga
可靠消息最终一致性方案

XA是我以前一直的观念，主要操作数据库，就是通过一个事务管理器，一旦出问题，就执行回滚，回滚各个系统的数据库，但是现在的系统一般允许动外部的数据库，所以渐渐不使用

TCC XA的升级版，去调用各个系统的接口去实现回滚，需要大量的代码去支持

以上都是==严格==的事务操作

常用的是可靠消息最终一致性方案

A系统和B系统，两个系统之前有一个消息中间键，A在执行前会给中间键发prepared信息，中间键此时会不停调用A系统，查询A的状态，A如果执行完毕，会给中间键发confirm，开始调用B系统。如果失败，就会触动回滚，

### 零拷贝的概念

就是数据传输的一种高效方式，数据从磁盘直接到用户内存，而不经过系统内存中转，以及CPU参与。

会用到DMA拷贝，也就是拷贝时不用CPU参与。

### 不对称加密的基本逻辑

生成了公钥和私钥，任务人都可以用公钥来进行加密，但只有私钥能进行解密。


### ThreadLocal的底层实现

会获取当前线程thread中的threadlocalmap属性，如果存在就更新value值，如果不存在，就初始化。
而threadlocalmap是thread定义的内部静态类

#### MVCC面试到底该怎么说，艹

**多版本并发控制** 技术的英文全称是 **Multiversion Concurrency Control**

是一种乐观锁

功能主要，事务在执行时，对数据生成快照，这样即使对应的数据发生变化，也不受影响

他还有个可见性算法，能根据不同隔离级别进行版本控制。这里不写了，不可能记住

### 为什么mysql表超过2000w，性能就会急速下降
>[!note] 
>MySQL默认是16K的页面，抛开它的配置header，大概就是15K，因此，非叶子节点的索引页面可放15*1024/12=1280条数据，按照每行1K计算，每个叶子节点可以存15条数据。同理，三层就是15*1280*1280=24576000条数据。只有数据量达到24576000条时，深度才会增加为4

因为正常b+树的结构深度为3 ，如果超过两千万就会变成4，性能急速下降

### Redis实现分布式锁

第一个最普通的实现方式，就是在 Redis 里使用 `SET key value [EX seconds] [PX milliseconds] NX` 创建一个 key，这样就算加锁。其中：

-   `NX`：表示只有 `key` 不存在的时候才会设置成功，如果此时 redis 中存在这个 `key`，那么设置失败，返回 `nil`。
-   `EX seconds`：设置 `key` 的过期时间，精确到秒级。意思是 `seconds` 秒后锁自动释放，别人创建的时候如果发现已经有了就不能加锁了。
-   `PX milliseconds`：同样是设置 `key` 的过期时间，精确到毫秒级。
注意：这里的value是随机数，防止超时后，把其他线程的锁解了，因此解锁是需要比对value值

但是这是单节点的，不实用

第二个是多节点redis锁
在n/2+1的节点上建立锁
如果建立时间小于超时时间就算建立成功
失败就把其他节点建好的删了


#### Redis6.0的多线程
只是网络请求和返回使用了多线程
而数据读写还是使用单线程


### mysql的buffer pool

是指外部系统和存储引擎之间的一个缓存区

采用LRU算法对数据进行加载


### DDD面试怎么说

分为两大块，分别为战略和战术
战略主要从全局入手，分析业务，划分领域，上下文等等
战术则侧重技术落地 聚合，实体领域服务等


### 联合索引从左匹配失效
特殊情况，所查字段全都是联合索引字段，这样会全表扫描索引，index类型

### ES简单概念

底层实现基于lucene（卢西恩），es存储数据的结构是：
index->type->mapping->document->field
index相当于mysql的表，document相当于行数据
type相当于表里的种类

#### 倒排索引

分词，记录词对应的文件id
![[Pasted image 20240319155420.png]]

搜索数据就是 输入关键词 通过倒排索引，找到对应的document id，再根据id找到节点，最后得到完整的document数据

es可以通过协调节点，通过哈希路由，转发到对应的node

### Spring失效的情况
1、异常不是runtiming error 等
2、异常被catch
3、传播机制不对
4、类未被spring管理
5、事务方法不是public
……