---
layout:     post
title:      HBase学习使用
date:       2018-04-06
author:     yunzhs
header-img: img/Fate of Princess.jpg
catalog: true
tags:
    - bigdata相关
typora-root-url: ..
typora-copy-images-to: ..\img\posts
---

# 一.hbase数据库介绍

## 1.简介

hbase是基于Google BigTable模型开发的，典型的key/value系统。是建立在hdfs之上，提供高可靠性、高性能、

列存储、可伸缩、实时读写nosql的数据库系统。它是Apache Hadoop生态系统中的重要一员，主要用于海量结构

化和半结构化数据存储。

它介于nosql和RDBMS之间，仅能通过主键(row key)和主键的range来检索数据，仅支持单行事务(可通过hive支

持来实现多表join等复杂操作)。

Hbase查询数据功能很简单，不支持join等复杂操作，不支持复杂的事务（行级的事务）

与hadoop一样，Hbase目标主要依靠横向扩展，通过不断增加廉价的商用服务器，来增加计算和存储能力。



### 1.1HBase中的表一般有这样的特点：

- 大：一个表可以有上十亿行，上百万列
- 无模式：每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一张表中不同的行可以有截然不同的列；
- 面向列:面向列(族)的存储和权限控制，列(族)独立检索。
- 稀疏:对于为空(null)的列，并不占用存储空间，因此，表可以设计的非常稀疏。
- 数据多版本：每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳-²  数据类型单一：Hbase中的数据都是字节数组byte[]。

### 1.2.表结构的逻辑视图

HBase以表的形式存储数据。表有行和列组成。列划分为若干个列族(column family)

![52299608290](/img/posts/1522996082909.png)

### 1.3.Row Key

与nosql数据库们一样,row key是用来检索记录的主键。访问hbase table中的行，只有三种方式：

1 通过单个row key访问

2 通过row key的range

3 全表扫描

Row key行键 (Row key)可以是任意字符串(最大长度是 64KB，实际应用中长度一般为 10-100bytes)，在hbase内

部，row key保存为字节数组。

**Hbase**会对表中的数据按照rowkey排序**字典顺序**

存储时，数据按照Row key的字典序(byte order)排序存储。设计key时，要充分排序存储这个特性，将经常一起读取的行存储放到一起。(位置相关性)

注意：

字典序对int排序的结果是

1,10,100,11,12,13,14,15,16,17,18,19,2,20,21,…,9,91,92,93,94,95,96,97,98,99。

要保持整形的自然序，行键必须用0作左填充。

行的一次读写是原子操作 (不论一次读写多少列)。这个设计决策能够使用户很容易的理解程序在对同一个行进行并发更新操作时的行为。

### 1.4.列族

hbase表中的每个列，都归属与某个列族。列族是表的schema的一部分(而列不是)，必须在使用表之前定义。

列名都以列族作为前缀。例如courses:history ， courses:math 都属于 courses 这个列族。

访问控制、磁盘和内存的使用统计都是在列族层面进行的。

列族越多，在取一行数据时所要参与IO、搜寻的文件就越多，所以，如果没有必要，不要设置太多的列族。一般设置2-3个比较合理。

### 1.5.时间戳

HBase中通过row和columns确定的为一个存贮单元称为cell。每个 cell都保存着同一份数据的多个版本。版本通

过时间戳来索引。时间戳的类型是 64位整型。时间戳可以由hbase(在数据写入时自动 )赋值，此时时间戳是精确

到毫秒的当前系统时间。时间戳也可以由客户显式赋值。如果应用程序要避免数据版本冲突，就必须自己生成具有

唯一性的时间戳。每个 cell中，不同版本的数据按照时间倒序排序，即**最新的数据**排在最前面。



为了避免数据存在过多版本造成的的管理 (包括存贮和索引)负担，hbase提供了两种数据版本回收方式：

- 保存数据的最后n个版本
- 保存最近一段时间内的版本（设置数据的生命周期TTL）。

用户可以针对每个列族进行设置。

### 1.6.cell

由{row key, column(=<family> + <label>), version} 唯一确定的单元。

cell中的数据是没有类型的，全部是字节码形式存贮。

## 2.hbase集群结构

![52299826127](/img/posts/1522998261272.png)

Hbase基本组件说明：

 

  **Client**：
  包含访问Hbase的接口，并维护cache来加快对Hbase的访问，比如region的位置信息。

  **HMaster**：
  是hbase集群的主节点，可以配置多个，用来实现HA
  为RegionServer分配region
  负责RegionServer的负载均衡
  发现失效的RegionServer并重新分配其上的region

  **RegionServer**：
  Regionserver维护region，处理对这些region的IO请求
  Regionserver负责切分在运行过程中变得过大的region

  **Region:**
  分布式存储的最小单元。

  **Zookeeper**作用:
  通过选举，保证任何时候，集群中只有一个活着的HMaster，HMaster与RegionServers 启动时会向ZooKeeper注册

  存贮所有Region的寻址入口

  实时监控Region server的上线和下线信息。并实时通知给HMaster存储HBase的schema和table元数据

  Zookeeper的引入使得HMaster不再是单点故障

## 3.hbase集群搭建

```
1.上传hbase安装包
	hbase-1.2.1-bin.tar.gz
2.解压
    tar -zxvf hbase-1.2.1-bin.tar.gz -C /var/loca/
	mv hbase-1.2.1-bin hbase
3.配置hbase集群，要修改3个文件（首先zk集群已经安装好了）
	注意：要把hadoop的hdfs-site.xml和core-site.xml 放到hbase/conf下
	
	3.1修改hbase-env.sh
	export JAVA_HOME=/export/servers/jdk
	//告诉hbase使用外部的zk
	export HBASE_MANAGES_ZK=false
	
	vim hbase-site.xml
	<configuration>
		<!-- 指定hbase在HDFS上存储的路径 -->
        <property>
                <name>hbase.rootdir</name>
                <value>hdfs://node-01:9000/hbase</value>
        </property>
		<!-- 指定hbase是分布式的 -->
        <property>
                <name>hbase.cluster.distributed</name>
                <value>true</value>
        </property>
		<!-- 指定zk的地址，多个用“,”分割 -->
        <property>
                <name>hbase.zookeeper.quorum</name>
                <value>node-01:2181,node-02:2181,node-03:2181</value>
        </property>
	</configuration>
	
	vim regionservers
		node-02
		node-03
	
	3.2 修改 backup-masters来指定备用的主节点
		[root@node1 conf]# vi backup-masters
							  node-02
	
	3.3 拷贝hbase到其他节点
		scp -r /export/servers/hbase  node-02:/export/servers/
		scp -r /export/servers/hbase  node-03:/export/servers/
4.将配置好的HBase拷贝到每一个节点并同步时间。
	ntpdate -u cn.pool.ntp.org
5.启动所有的hbase
	分别启动zk
		./zkServer.sh start
	启动hbase集群
		start-dfs.sh
	启动hbase，在node1 master主节点上运行：
		start-hbase.sh
6.通过浏览器访问hbase管理页面
	node1:16010
    node2:16010  
7.为保证集群的可靠性，要启动多个HMaster
	hbase-daemon.sh start master
```

注意：使用jdk8的时候，出现了Java
HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=256m; support
was removed in 8.0的红色标识。

因此需要在hbase-env.sh中的相关配置注释掉即可

## 4.命令行操作

### 基本shell操作

```
进入hbase命令行
./hbase shell

显示hbase中的表
list

创建user表，包含info、data两个列族
create 'user', 'info', 'data'   
或者
create 'user', {NAME => 'info', VERSIONS => '3'}，{NAME => 'data'}

向user表中插入信息，row key为rk0001，列族info中添加name列标示符，值为zhangsan
put 'user', 'rk0001', 'info:name', 'zhangsan'

向user表中插入信息，row key为rk0001，列族info中添加gender列标示符，值为female
put 'user', 'rk0001', 'info:gender', 'female'

向user表中插入信息，row key为rk0001，列族info中添加age列标示符，值为20
put 'user', 'rk0001', 'info:age', 20

向user表中插入信息，row key为rk0001，列族data中添加pic列标示符，值为picture
put 'user', 'rk0001', 'data:pic', 'picture'

获取user表中row key为rk0001的所有信息
get 'user', 'rk0001'

获取user表中row key为rk0001，info列族的所有信息
get 'user', 'rk0001', 'info'

获取user表中row key为rk0001，info列族的name、age列标示符的信息
get 'user', 'rk0001', 'info:name', 'info:age'

获取user表中row key为rk0001，info、data列族的信息
get 'user', 'rk0001', 'info', 'data'
get 'user', 'rk0001', {COLUMN => ['info', 'data']}

get 'user', 'rk0001', {COLUMN => ['info:name', 'data:pic']}

获取user表中row key为rk0001，列族为info，版本号最新5个的信息
get 'user', 'rk0001', {COLUMN => 'info', VERSIONS => 2}
get 'user', 'rk0001', {COLUMN => 'info:name', VERSIONS => 5}
get 'user', 'rk0001', {COLUMN => 'info:name', VERSIONS => 5, TIMERANGE => [1392368783980, 1392380169184]}

获取user表中row key为rk0001，cell的值为zhangsan的信息
get 'people', 'rk0001', {FILTER => "ValueFilter(=, 'binary:zhangsan')"}

获取user表中row key为rk0001，列标示符中含有a的信息
get 'people', 'rk0001', {FILTER => "(QualifierFilter(=,'substring:a'))"}

put 'user', 'rk0002', 'info:name', 'fanbingbing'
put 'user', 'rk0002', 'info:gender', 'female'
put 'user', 'rk0002', 'info:nationality', '中国'
get 'user', 'rk0002', {FILTER => "ValueFilter(=, 'binary:中国')"}


查询user表中的所有信息
scan 'user'

查询user表中列族为info的信息
scan 'user', {COLUMNS => 'info'}
scan 'user', {COLUMNS => 'info', RAW => true, VERSIONS => 5}
scan 'persion', {COLUMNS => 'info', RAW => true, VERSIONS => 3}

查询user表中列族为info和data的信息
scan 'user', {COLUMNS => ['info', 'data']}
scan 'user', {COLUMNS => ['info:name', 'data:pic']}

查询user表中列族为info、列标示符为name的信息
scan 'user', {COLUMNS => 'info:name'}

查询user表中列族为info、列标示符为name的信息,并且版本最新的5个
scan 'user', {COLUMNS => 'info:name', VERSIONS => 5}

查询user表中列族为info和data且列标示符中含有a字符的信息
scan 'user', {COLUMNS => ['info', 'data'], FILTER => "(QualifierFilter(=,'substring:a'))"}

查询user表中列族为info，rk范围是[rk0001, rk0003)的数据
scan 'people', {COLUMNS => 'info', STARTROW => 'rk0001', ENDROW => 'rk0003'}

查询user表中row key以rk字符开头的
scan 'user',{FILTER=>"PrefixFilter('rk')"}

查询user表中指定范围的数据
scan 'user', {TIMERANGE => [1392368783980, 1392380169184]}

删除数据
删除user表row key为rk0001，列标示符为info:name的数据
delete 'people', 'rk0001', 'info:name'
删除user表row key为rk0001，列标示符为info:name，timestamp为1392383705316的数据
delete 'user', 'rk0001', 'info:name', 1392383705316

清空user表中的数据
truncate 'people'

修改表结构
首先停用user表
disable 'user'

添加两个列族f1和f2
alter 'people', NAME => 'f1'
alter 'user', NAME => 'f2'

启用表
enable 'user'

删除一个列族：
alter 'user', NAME => 'f1', METHOD => 'delete' 或 alter 'user', 'delete' => 'f1'

添加列族f1同时删除列族f2
alter 'user', {NAME => 'f1'}, {NAME => 'f2', METHOD => 'delete'}

将user表的f1列族版本号改为5
alter 'people', NAME => 'info', VERSIONS => 5
启用表
enable 'user'

删除表
disable 'user'
drop 'user'

查询数据
get 'person', 'rk0001', {FILTER => "ValueFilter(=, 'binary:中国')"}
get 'person', 'rk0001', {FILTER => "(QualifierFilter(=,'substring:a'))"}
scan 'person', {COLUMNS => 'info:name'}
scan 'person', {COLUMNS => ['info', 'data'], FILTER => "(QualifierFilter(=,'substring:a'))"}
scan 'person', {COLUMNS => 'info', STARTROW => 'rk0001', ENDROW => 'rk0003'}

scan 'person', {COLUMNS => 'info', STARTROW => '20140201', ENDROW => '20140301'}
scan 'person', {COLUMNS => 'info:name', TIMERANGE => [1395978233636, 1395987769587]}
delete 'person', 'rk0001', 'info:name'

alter 'person', NAME => 'ffff'
alter 'person', NAME => 'info', VERSIONS => 10


get 'user', 'rk0002', {COLUMN => ['info:name', 'data:pic']}
```

## 5.hbase代码开发(基本,过滤器查询)

### 5.1.基本增删改查java实现

```
public class HbaseDemo {

	private Configuration conf = null;
	
	@Before
	public void init(){
		conf = HBaseConfiguration.create();
		conf.set("hbase.zookeeper.quorum", "itcast01:2181,itcast02:2181,itcast03:2181");
	}
	
	@Test
	public void testDrop() throws Exception{
		HBaseAdmin admin = new HBaseAdmin(conf);
		admin.disableTable("account");
		admin.deleteTable("account");
		admin.close();
	}
	
	@Test
	public void testPut() throws Exception{
		HTable table = new HTable(conf, "person_info");
		Put p = new Put(Bytes.toBytes("person_rk_bj_zhang_000002"));
		p.add("base_info".getBytes(), "name".getBytes(), "zhangwuji".getBytes());
		table.put(p);
		table.close();
	}
	

	@Test
	public void testDel() throws Exception{
		HTable table = new HTable(conf, "user");
		Delete del = new Delete(Bytes.toBytes("rk0001"));
		del.deleteColumn(Bytes.toBytes("data"), Bytes.toBytes("pic"));
		table.delete(del);
		table.close();
	}

	@Test
	public void testGet() throws Exception{
		HTable table = new HTable(conf, "person_info");
		Get get = new Get(Bytes.toBytes("person_rk_bj_zhang_000001"));
		get.setMaxVersions(5);
		Result result = table.get(get);
		
		List<Cell> cells = result.listCells();
	
		for(Cell c:cells){
		}
		
		//result.getValue(family, qualifier);  可以从result中直接取出一个特定的value
		
		//遍历出result中所有的键值对
		List<KeyValue> kvs = result.list();
		//kv  ---> f1:title:superise....      f1:author:zhangsan    f1:content:asdfasldgkjsldg
		for(KeyValue kv : kvs){
			String family = new String(kv.getFamily());
			System.out.println(family);
			String qualifier = new String(kv.getQualifier());
			System.out.println(qualifier);
			System.out.println(new String(kv.getValue()));
			
		}
		table.close();
	}

```

### 5.2.过滤器查询

#### 引言：

过滤器的类型很多，但是可以分为两大类——比较过滤器，专用过滤器
过滤器的作用是在服务端判断数据是否满足条件，然后只将满足条件的数据返回给客户端；

hbase过滤器的比较运算符：

```
LESS  <
LESS_OR_EQUAL <=
EQUAL =
NOT_EQUAL <>
GREATER_OR_EQUAL >=
GREATER >
NO_OP 排除所有
```

Hbase过滤器的比较器（指定比较机制）：

```
BinaryComparator  按字节索引顺序比较指定字节数组，采用Bytes.compareTo(byte[])
BinaryPrefixComparator 跟前面相同，只是比较左端的数据是否相同
NullComparator 判断给定的是否为空
BitComparator 按位比较
RegexStringComparator 提供一个正则的比较器，仅支持 EQUAL 和非EQUAL
SubstringComparator 判断提供的子串是否出现在value中。
```

####  比较过滤器

1.1  行键过滤器RowFilter

 ```
Filter filter1 = new RowFilter(CompareOp.LESS_OR_EQUAL, new BinaryComparator(Bytes.toBytes("row-22")));  
scan.setFilter(filter1)
 ```

1.2  列族过滤器FamilyFilter

 ```
Filter filter1 = new FamilyFilter(CompareFilter.CompareOp.LESS, new BinaryComparator(Bytes.toBytes("colfam3")));
scan.setFilter(filter1);  
 ```

1.3 列过滤器QualifierFilter

 ```
filter = new QualifierFilter(CompareFilter.CompareOp.LESS_OR_EQUAL, new BinaryComparator(Bytes.toBytes("col-2")));
scan.setFilter(filter1);
 ```

1.4 值过滤器ValueFilter  

```
Filter filter = new ValueFilter(CompareFilter.CompareOp.EQUAL, new SubstringComparator(".4") );  
scan.setFilter(filter1);  
```

1.5.多种过滤器

```
	/**
	 * 多种过滤条件的使用方法
	 * @throws Exception
	 */
	@Test
	public void testScan() throws Exception{
		HTable table = new HTable(conf, "person_info".getBytes());
		Scan scan = new Scan(Bytes.toBytes("person_rk_bj_zhang_000001"), Bytes.toBytes("person_rk_bj_zhang_000002"));
		
		//前缀过滤器----针对行键
		Filter filter = new PrefixFilter(Bytes.toBytes("rk"));
		
		//行过滤器  ---针对行键
		ByteArrayComparable rowComparator = new BinaryComparator(Bytes.toBytes("person_rk_bj_zhang_000001"));
		RowFilter rf = new RowFilter(CompareOp.LESS_OR_EQUAL, rowComparator);
		
		/**
         * 假设rowkey格式为：创建日期_发布日期_ID_TITLE
         * 目标：查找  发布日期  为  2014-12-21  的数据
         */
        rf = new RowFilter(CompareOp.EQUAL , new SubstringComparator("_2014-12-21_"));
		
		
		//单值过滤器1完整匹配字节数组
		new SingleColumnValueFilter("base_info".getBytes(), "name".getBytes(), CompareOp.EQUAL, "zhangsan".getBytes());
		//单值过滤器2 匹配正则表达式
		ByteArrayComparable comparator = new RegexStringComparator("zhang.");
		new SingleColumnValueFilter("info".getBytes(), "NAME".getBytes(), CompareOp.EQUAL, comparator);

		//单值过滤器3匹配是否包含子串,大小写不敏感
		comparator = new SubstringComparator("wu");
		new SingleColumnValueFilter("info".getBytes(), "NAME".getBytes(), CompareOp.EQUAL, comparator);

		//键值对元数据过滤-----family过滤----字节数组完整匹配
        FamilyFilter ff = new FamilyFilter(
                CompareOp.EQUAL , 
                new BinaryComparator(Bytes.toBytes("base_info"))   //表中不存在inf列族，过滤结果为空
                );
        //键值对元数据过滤-----family过滤----字节数组前缀匹配
        ff = new FamilyFilter(
                CompareOp.EQUAL , 
                new BinaryPrefixComparator(Bytes.toBytes("inf"))   //表中存在以inf打头的列族info，过滤结果为该列族所有行
                );
        
       //键值对元数据过滤-----qualifier过滤----字节数组完整匹配
        
        filter = new QualifierFilter(
                CompareOp.EQUAL , 
                new BinaryComparator(Bytes.toBytes("na"))   //表中不存在na列，过滤结果为空
                );
        filter = new QualifierFilter(
                CompareOp.EQUAL , 
                new BinaryPrefixComparator(Bytes.toBytes("na"))   //表中存在以na打头的列name，过滤结果为所有行的该列数据
        		);
		
        //基于列名(即Qualifier)前缀过滤数据的ColumnPrefixFilter
        filter = new ColumnPrefixFilter("na".getBytes());
        
        //基于列名(即Qualifier)多个前缀过滤数据的MultipleColumnPrefixFilter
        byte[][] prefixes = new byte[][] {Bytes.toBytes("na"), Bytes.toBytes("me")};
        filter = new MultipleColumnPrefixFilter(prefixes);
 
        //为查询设置过滤条件
        scan.setFilter(filter);
       
        
		scan.addFamily(Bytes.toBytes("base_info"));
		//一行
//		Result result = table.get(get);
		//多行的数据
		ResultScanner scanner = table.getScanner(scan);
		for(Result r : scanner){
			/**
			for(KeyValue kv : r.list()){
				String family = new String(kv.getFamily());
				System.out.println(family);
				String qualifier = new String(kv.getQualifier());
				System.out.println(qualifier);
				System.out.println(new String(kv.getValue()));
			}
			*/
			//直接从result中取到某个特定的value
			byte[] value = r.getValue(Bytes.toBytes("base_info"), Bytes.toBytes("name"));
			System.out.println(new String(value));
		}
		table.close();
	}

```

## 6.hbase内部原理

![52306799011](/img/posts/1523067990114.png)

Client

1 包含访问hbase的接口，client维护着一些cache来加快对hbase的访问，比如region的位置信息。

 

Zookeeper

1 保证任何时候，集群中只有一个master

2 存贮所有Region的寻址入口----root表在哪台服务器上。

3 实时监控RegionServer的状态，将Region server的上线和下线信息实时通知给Master

4 存储Hbase的schema,包括有哪些table，每个table有哪些column family

 

Master职责

1 为Region server分配region

2 负责region server的负载均衡

3 发现失效的regionserver并重新分配其上的region

4 HDFS上的垃圾文件回收

5 处理schema更新请求

 

Region Server职责

1 Region server维护Master分配给它的region，处理对这些region的IO请求

2 Region server负责切分在运行过程中变得过大的region

可以看到，client访问hbase上数据的过程并不需要master参与（寻址访问zookeeper和region server，数据读写访问regione server），master仅仅维护者table和region的元数据信息，负载很低。

 ![52307334239](/img/posts/1523073342393.png)

补充:

bloomfileter(布隆过滤器)

用来在做读数据时,对相应的行列进行过滤,位于列族的memstore中找不到,就从相应的storefile中找的过程



# 二.Hbase高级应用

## 1.建表高级属性

​	下面几个shell 命令在hbase操作中可以起到很到的作用，且主要体现在建表的过程中，看下面几个create 属性

### 1、BLOOMFILTER  

默认是NONE 是否使用布隆过虑及使用何种方式

布隆过滤可以每列族单独启用。

使用 HColumnDescriptor.setBloomFilterType(NONE | ROW | ROWCOL) 对列族单独启用布隆。 

²  Default = ROW 对行进行布隆过滤。

²  对 ROW，行键的哈希在每次插入行时将被添加到布隆。

²  对 ROWCOL，行键 + 列族 + 列族修饰的哈希将在每次插入行时添加到布隆

   使用方法: create'table',{BLOOMFILTER =>'ROW'} 

   启用布隆过滤可以节省读磁盘过程，可以有助于降低读取延迟 

 

### 2、VERSIONS 

默认是1 这个参数的意思是数据保留1个版本，如果我们认为我们的数据没有这么大的必要保留这么多，随时都在更新，而老版本的数据对我们毫无价值，那将此参数设为1 能节约2/3的空间

使用方法: create 'table',{VERSIONS=>'2'}

 

附：MIN_VERSIONS => '0'是说在compact操作执行之后，至少要保留的版本

 

### 3、COMPRESSION

默认值是NONE 即不使用压缩

​     这个参数意思是该列族是否采用压缩，采用什么压缩算法

​     使用方法: create'table',{NAME=>'info',COMPRESSION=>'SNAPPY'} 

​     建议采用SNAPPY压缩算法 

​    HBase中，在Snappy发布之前（Google 2011年对外发布Snappy），采用的LZO算法，目标是达到尽可能快的压缩和解压速度，同时减少对CPU的消耗；

​    在Snappy发布之后，建议采用Snappy算法（参考《HBase: The Definitive Guide》），具体可以根据实际情况对LZO和Snappy做过更详细的对比测试后再做选择。

​                    

| **Algorithm** | **% remaining** | **Encoding** | **Decoding** |
| ------------- | --------------- | ------------ | ------------ |
| GZIP          | 13.4%           | 21 MB/s      | 118 MB/s     |
| LZO           | 20.5%           | 135 MB/s     | 410 MB/s     |
| Zippy/Snappy  | 22.2%           | 172 MB/s     | 409 MB/s     |

如果建表之初没有压缩，后来想要加入压缩算法，可以通过alter修改schema

 

### 4、alter 

​     使用方法：

​     如 修改压缩算法      

​      disable 'table'

​      alter'table',{NAME=>'info',COMPRESSION=>'snappy'} 

​      enable 'table'

​     但是需要执行major_compact'table' 命令之后 才会做实际的操作。

 

### 5、TTL 

默认是 2147483647 即:Integer.MAX_VALUE 值大概是68年

这个参数是说明该列族数据的存活时间，单位是s 

这个参数可以根据具体的需求对数据设定存活时间，超过存过时间的数据将在表中不在显示，待下次major compact的时候再彻底删除数据.

注意的是TTL设定之后 MIN_VERSIONS=>'0' 这样设置之后，TTL时间戳过期后，将全部彻底删除该family下所有的数据，如果MIN_VERSIONS 不等于0那将保留最新的MIN_VERSIONS个版本的数据，其它的全部删除，比如MIN_VERSIONS=>'1' 届时将保留一个最新版本的数据，其它版本的数据将不再保存。

 

### 6、describe 'table' 

这个命令查看了create table 的各项参数或者是默认值。

 

### 7、disable_all  'toplist.*' disable_all

 支持正则表达式，并列出当前匹配的表的如下：

​     toplist_a_total_1001                                                                                                                                                

​     toplist_a_total_1002                                                                                                                                               

​     toplist_a_total_1008                                                                                                                                               

​     toplist_a_total_1009                                                                                                                                               

​     toplist_a_total_1019                                                                                                                                               

​     toplist_a_total_1035

​    ...

​    Disable the above 25 tables (y/n)? 并给出确认提示.

### 8、drop_all

这个命令和disable_all的使用方式是一样的

 

### 9、hbase 表预分区----手动分区

​     默认情况下，在创建HBase表的时候会自动创建一个region分区，当导入数据的时候，所有的HBase客户端都向这一个region写数据，直到这个region足够大了才进行切分。一种可以加快批量写入速度的方法是通过预先创建一些空的regions，这样当数据写入HBase时，会按照region分区情况，在集群内做数据的负载均衡。

命令方式:

create't1', 'f1', {NUMREGIONS => 15, SPLITALGO => 'HexStringSplit'}

也可以使用api的方式: 

​    bin/hbase org.apache.hadoop.hbase.util.RegionSplitter test_tableHexStringSplit -c 10 -f info  

​     参数：

​        test_table是表名 

HexStringSplit 是split 方式

-c是分10个region 

-f是family

 

可在UI上查看结果，如图：

![img](/img/posts/1523100127526.png) 

​     这样就可以将表预先分为15个区，减少数据达到storefile 大小的时候自动分区的时间消耗，并且还有以一个优势，就是合理设计rowkey能让各个region 的并发请求平均分配(趋于均匀) 使IO 效率达到最高，但是预分区需要将filesize 设置一个较大的值，设置哪个参数呢, hbase.hregion.max.filesize 这个值默认是10G 也就是说单个region默认大小是10G,

​     这个参数的默认值在0.90到0.92到0.94.3各版本的变化：256M--1G--10G

​     但是如果MapReduceInput类型为TableInputFormat 使用hbase作为输入的时候，就要注意了，每个region一个map，如果数据小于10G 那只会启用一个map 造成很大的资源浪费，这时候可以考虑适当调小该参数的值，或者采用预分配region的方式，并将检测如果达到这个值，再手动分配region。

## 2.HBase的设计原则

HBase是三维有序存储的，通过**rowkey（行键）**，**column key（column family和qualifier）**和**TimeStamp（时间戳）**这个三个维度可以对HBase中的数据进行快速定位。

HBase中rowkey可以唯一标识一行记录，在HBase查询的时候，有以下几种方式：

1. 通过get方式，指定rowkey获取唯一一条记录


2. 通过scan方式，设置startRow和stopRow参数进行范围匹配


3. 全表扫描，即直接扫描整张表中所有行记录

### 2.1.rowkey长度原则

rowkey是一个二进制码流，可以是任意字符串，最大长度64kb，实际应用中一般为10-100bytes，以byte[]形式保存，一般设计成定长。

建议越短越好，不要超过16个字节，原因如下：

- 数据的持久化文件HFile中是按照KeyValue存储的，如果rowkey过长，比如超过100字节，1000w行数据，光rowkey就要占用100*1000w=10亿个字节，将近1G数据，这样会极大影响HFile的存储效率；
- MemStore将缓存部分数据到内存，如果rowkey字段过长，内存的有效利用率就会降低，系统不能缓存更多的数据，这样会降低检索效率。


### 2.2.rowkey散列原则

如果rowkey按照时间戳的方式递增，不要将时间放在二进制码的前面，建议将rowkey的高位作为散列字段，由程

序随机生成，低位放时间字段，这样将提高数据**均衡分布**在每个RegionServer，以实现负载均衡的几率。如果没

有散列字段，首字段直接是时间信息，所有的数据都会集中在一个RegionServer上，这样在数据检索的时候负载

会集中在个别的RegionServer上，造成热点问题，会降低查询效率。

rowkey是按字典序排序的,从而来划分region,因此如果是散列的话,可以有均衡分布的效果

### 2.3.rowkey唯一原则

必须在设计上保证其唯一性，rowkey是按照字典顺序排序存储的，因此，设计rowkey的时候，要充分利用这个排

序的特点，将经常读取的数据存储到一块，将最近可能会被访问的数据放到一块。

### 2.4.什么是热点?

HBase中的行是按照rowkey的字典顺序排序的，这种设计优化了scan操作，可以将相关的行以及会被一起读取的

行存取在临近位置，便于scan。然而**糟糕的rowkey设计是热点的源头**。 我们需要做的是避免热点



热点发生在大量的client直接访问集群的一个或极少数个节点（访问可能是读，写或者其他操作）。**大量访问会使**

**单个热点region所在的单个机器超出自身承受能力**，引起性能下降甚至region不可用，这也会影响同一个

RegionServer上的其他region，由于主机无法服务其他region的请求。 



设计良好的数据访问模式以使集群被充分，均衡的利用。为了**避免写热点**，设计rowkey使得**不同行在同一个**

**region**，但是在更多数据情况下，数据应该被写入集群的多个region，而不是一个。下面是一些常见的避免热点

的方法以及它们的优缺点：

#### 2.4.1.**加盐**

这里所说的加盐不是密码学中的加盐，而是在rowkey的前面增加随机数，具体就是给rowkey分配一个随机前缀以

使得它和之前的rowkey的开头不同。分配的前缀种类数量应该和你想使用数据分散到不同的region的数量一致。

加盐之后的rowkey就会根据随机生成的前缀分散到各个region上，以避免热点。

#### 2.4.2.哈希

哈希会使同一行永远用一个前缀加盐。哈希也可以使负载分散到整个集群，但是读却是可以预测的。使用确定的哈

希可以让客户端重构完整的rowkey，可以使用get操作准确获取某一个行数据

#### 2.4.3.**反转**

第三种防止热点的方法时反转固定长度或者数字格式的rowkey。这样可以使得rowkey中经常改变的部分（最没有

意义的部分）放在前面。这样可以有效的随机rowkey，但是牺牲了rowkey的有序性。

**反转rowkey的例子以手机号为rowkey**，可以将手机号反转后的字符串作为rowkey，这样的就避免了以手机号那

样比较固定开头导致热点问题

#### 2.4.4.时间戳反转

一个常见的数据处理问题是快速获取数据的最近版本，使用反转的时间戳作为rowkey的一部分对这个问题十分有

用，可以用 Long.Max_Value - timestamp 追加到key的末尾，例如 \[key][reverse_timestamp] , [key] 的最新值可以通过scan [key]获得

[key]的第一条记录，因为HBase中rowkey是有序的，第一条记录是最后录入的数据。

#### 其他一些建议：

尽量减少行和列的大小在HBase中，value永远和它的key一起传输的。当具体的值在系统间传输时，它的

rowkey，列名，时间戳也会一起传输。如果你的rowkey和列名很大，甚至可以和具体的值相比较，那么你将会遇

到一些有趣的问题。HBase storefiles中的索引（有助于随机访问）最终占据了HBase分配的大量内存，因为具体

的值和它的key很大。可以增加block大小使得storefiles索引再更大的时间间隔增加，或者修改表的模式以减小

rowkey和列名的大小。压缩也有助于更大的索引。

列族尽可能越短越好，最好是一个字符，冗长的属性名虽然可读性好，但是更短的属性名存储在HBase中会更好。

