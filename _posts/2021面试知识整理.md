---
typora-root-url: ..
typora-copy-images-to: ../img/posts
---

##### redis为什么快：

- 因为redis的数据是存在内存里的;

- Redis的数据结构简单，都是比较基础的数据类别，比如键值对，链表等：string是sds数据结构，有len，free，buf(保存具体字节)几个字段

- **Redis数据结构的选取非常合适，采用全局的链式哈希表进行存储每一个key-value**，同时，Redis对于哈希扩容的处理也很高效，查询时间非常快，是趋近于O（1）的，并且当哈希桶使用个数比较多时，会进行哈希表的扩容，避免时间复杂度的增高。redis采用渐进式扩容的策略，redis中默认会有两张全局的哈希表（存放哈希值的就是哈希表），一开始所有的key-value都存储在第一张哈希表中，当第一张哈希表存储的元素过多。会用第二张哈希表进行扩容，然后第一张哈希表的元素重新映射到第二张哈希表中。第一张哈希表留作下一次扩容备用。

  但是这样会存在一个问题，数据在迁移的过程中，是非常耗时的操作！很有可能造成业务堵塞。那redis是怎么做的呢？

  redis是这么做的，每次处理一个请求，就重新映射一个哈希桶的元素到另一张哈希表中，所以这样一来，就让每个请求分摊了哈希重新映射的时间。而不会造成业务的堵塞，只是让某些用户的请求变慢了一些。**同时redis维护了一个定时器，会周期性的进行数据的重新映射。**

- 单线程的，cpu不是瓶颈，内存大小才是
  - redis6.0之后开始支持多线程，但多线程是默认禁用的，线程核也不能超过8个否则意义不大
  - 多线程会导致的问题，线程切换、加锁解锁带来的资源损耗，执行顺序问题，多线程间的死锁问题
  - 之所以支持多线程是为了解决网络I/O带来的CPU的耗时，充分利用cpu的资源，减少I/O阻塞带来的性能损耗
  
- 采用多路io流复用模型，非阻塞Io流，只多个网络连接共用一个线程，减少io切换时的压力。**本质上是因为提高了IO读写的效率**

- 在多路复用IO模型中，会有一个线程不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真正调用实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。

##### kafka的实现原理（相关知识）

- ack机制（设置0为不启用，1为客户端不确认，2为都确认），服务器收到确认，客户端再确认收到。主要解决可能的数据丢失问题。  配置了开启，因为对实时性要求不大。
- 

##### 接口优化方式

- 给网售接口，查询用redis做缓存

##### ribbon 

负载均衡策略，默认为轮询的策略，还有随机数，加权，根据负载情况等方式

##### innodb和mylSam区别

- 主要区别是innodb支持事务和外键，因此innodb适合(写入多的)，因为数据的一致性更能有保证。

- innodb支持表、行(默认)锁，mylsam支持表锁

- Innodb不保存行数，因为查行数的时候需要全表扫描。

- 主键必须用聚集索引，mylsam不需要

  B+树是平衡二叉树的升级版，平衡多叉树

##### MySQL的索引

- 为什么用b+树？ 
  - B+树的结构特点是深度低，能有效减少查询次数
  
- 普通索引的查询方式
  - 先根据索引进行查询，如果索引中不包含所需要的的数据字段，则再根据索引中存储的主键值再进行一次查询
  
- 当创建(a,b,c)联合索引时，相当于创建了(a)单列索引，(a,b)联合索引以及(a,b,c)联合索引 

- 索引覆盖就是索引字段决定包含所查询的字段，从而不用回表操作

- 聚集索引和非聚集索引
  - 非聚集索引是指索引的数据与数据行物理排序顺序无关，基本上有几行数据，就有几行索引
    聚集索引是索引顺序决定数据行的物理顺序
  
- 索引失效原因
  - like从右开始匹配
  - 联合索引从右开始匹配
  - 字符类别查询时没加引号,导致隐形的类型转换
  - 在索引列进行数据运算
  
- explain判断是否走索引的标志extra的说明
  - using index 走索引，没有发生回表
  
  - null表示未被索引覆盖
  
  - using where 走索引，但是产生回表

  - using where;Using index 走索引，再根据where条件里的值去筛选，查的值都在索引里
  
  - using index condition 查询条件都是索引列，但是一部分查询条件不满足索引使用条件，如（模糊查询从左开始，类型转换啥的）还需要做进一步的匹配
  - 如下，联合索引为（zipcode，lastname，address）
  - zipcode走了索引，后面两个走不了
  - 所以本质上还是一种回表
```
1.    
    SELECT * FROM people
    
2.  WHERE zipcode='95054'
    
3.  AND lastname LIKE '%etrunia%'
    
4.  AND address LIKE '%Main Street%';
```
- explain语句中type字段的说明，只解释常见的六个类型，效率由低到高

  - all：全表扫描，效率最底下的一种

  - index：全表扫描，不过扫描的是索引列（SELECT  realname FROM company_user）

  - range：有一定范围的索引扫描> <,<>范围

  - ref：查询条件的列中使用了索引，有重复值也是在小范围内扫描

  -  ref_eq：唯一索引，找到就不会再往下面查了，是上面一个的升级版

  - const：常量查询，直接通过主键值等值查询

 explain执行**未执行的语句**时会**预估**，得到的结果时不准确的，因此要执行一次再使用explain

##### MySQL执行流程图

![mysql执行流程图](/img/posts/mysql执行流程图.png)

- 连接器，负责通信，校验权限
- 缓存，在读多写少的环境里效率会很低，因此8.0之后已经删除，5.6则是默认关闭
- 分析器，把关键字和非关键字提取出来，也会做一些校验。
- 优化器，执行计划生成，索引选择，如联合索引，如果写的时候没按从左到右顺序写，这里就会优化成顺序
- 执行器，调用存储引擎

##### MySQL深入理解

数据库是一条条数据去处理的

执行流程，server一次次的去调用存储引擎，存储引擎根据索引得到值后返回一条数据给server，server根据where条件去判断，符合就返回客户端，不符合就继续调存储引擎，直到结束

##### hashMap的数据结构

采用数组加链表的模式，在java8之后采用链表超过8之后用红黑树的模式，长度在变为6之后又退化为链表。

##### 红黑树

1）每个结点要么是红的，要么是黑的。

2）根结点是黑的。

3）每个叶结点（叶结点即指树尾端NIL指针或NULL结点）是黑的。

4）如果一个结点是红的，那么它的俩个儿子都是黑的。

5）对于任一结点而言，其到叶结点树尾端NIL指针的每一条路径都包含相同数目的黑结点。
14


Sleep不释放，wait释放

##### 水运项目的基本业务架构

航班计划 :基础信息 制定计划，
售票:票据 用户 售票  推送
检票: 检票，和港口数据同步
结算:银企直联 报表  支付

##### 快速排序(算法实现未来需要拿下)

取第一个数，从最后一个开始比较，找到一个比它小的，放在第一个，记录此时的位置序号，再从开始从开头比，找一个比它大的放那个序号的地方，记录序号，递归这个流程

算法思路：数组递归

参数（数据，头坐标，尾坐标）
方法里做比较和交换
直至剩一个数跳出


![快速排序](/img/posts/快速排序.jpeg)

##### 数据击穿，数据血崩， 数据穿透，布隆 

- 数据击穿，大并发一直访问一个数据，在数据过期后，大量请求直接访问数据库
  - 设置热点数据永不过期，有更新就更新缓存
  - 互斥锁
- 数据雪崩，大量数据同时过期，导致直接访问数据库
  - 过期时间设置为随机值
  - 修改为永不过期，有更新就更新缓存

    - 数据穿透：一直访问缓存里没有的数据，导致数据库压力很大
    - 布隆过滤器：使用一个BitSet数据结构(相比散列大大节省空间)，使用多个hash函数把set上的多个位置赋值为1，hash函数越多，误差值越低，
    - 布隆过滤器可以判断某个数据一定不存在，但无法判断其一定存在
    - 布隆过滤器需要初始化，因此一旦数据有更新就得及时更新布隆
    - 实用场景：判断url是否在亿级的黑名单里
    - 误判，建立白名单

##### 数据倾斜：

- 现象：

  指redis是集群部署的情况下，某个实例上分布的数据过多，超过负载的情况

- 解决方式

  - 手工分配slot，给其他机器分配相同或者更多slot过去
  - 给热点数据的key前面加随机数
  - 不使用bigkey(存在大数量的list元素)



##### map为什么要重写hashcode和equal函数

```
Key k1 = new Key(1);
Key k2 = new Key(1);
HashMap<Key,String> hm = new HashMap<Key,String>();
hm.put(k1, "Key with id is 1");    
System.out.println(hm.get(k2)); //这里正常应该得到上一行的的value，但是没重写的话就会得到null   
```

默认的hash存的都是对象的内存地址，默认的equals比的也是地址



##### string的hashcode计算

```
        int h=hash;
		for (int i = 0; i < value.length; i++) {
            h = 31 * h + val[i];
        }
        return h;
```

value为各个字符，int和char相加，char会变为ASCII码


##### 线程的生命周期

分为四种，分别为创建状态，就绪状态，阻塞状态，死亡状态： 

创建状态：指线程申请到内存空间，相当于就是new thread了，还没有执行start（）方法

就绪状态：指执行了start（）到run（）的阶段，执行start可能还需要等待分配了cpu才能正常执行run方法

阻塞状态：主要用两种分别是sleep()状态和wait()状态

销毁状态：执行完run()方法后

##### runnable和thread的区别

前者是接口，后者是接口的实现类，基本没啥区别

##### 事务的传播机制

一共有7种。

最重要的是*requierd(普通)，requierd_new( 新建事务，内外不关联)，nested(内嵌事务，外层是内层的上级)*

 *supports支持当前事务，不存在也支持*    *not_supported 以非事务执行，存在之前挂起*

 *mandatory 当前没事务就抛异常*         *never  以非事务执行，存在事务就抛异常*

##### 并行和并发的区别：

并行和并发都可能有多个线程去执行，并行指能同时进行，比如多个cpu，并发则是多个线程去用一个cpu

##### volatile关键字

volatile:当一个变量被volatile修饰时，对他的修改会立刻刷新到主存， 正常一个变量只会存到线程工作内存，这时如果主内存发生改变，那么线程工作内存不会改变

##### 多线程的执行顺序

1、通过join关键字，thread1.join(),启用后主线程放弃cpu控制权，直至thead1执行完毕

2、利用并发包里的Excutors的`newSingleThreadExecutor`产生一个单线程的线程池，而这个线程池的底层原理就是一个先进先出（FIFO）的队列。代码中executor.submit依次添加了123线程，按照FIFO的特性，执行顺序也就是123的执行结果，从而保证了执行顺序。

3、用countDownLatch计数来控制

总结来说，`CountDownLatch`的作用就是等待其他的线程都执行完任务，必要时可以对各个任务的执行结果进行汇总，然后主线程才继续往下执行。

latch.await()的意思是使当前线程等待，直到计数器值变为0，除非线程被 `interrupted`。如果计数器的值已经为0，则此方法立即返回。