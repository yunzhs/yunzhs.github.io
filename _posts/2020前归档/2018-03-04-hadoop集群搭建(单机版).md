---
layout:     post
title:      hadoop集群搭建(单机配置版)
date:       2017-09-14
author:     yunzhs
header-img: img/Fate of Princess.jpg
catalog: true
tags:
    - hadoop
typora-root-url: ..
typora-copy-images-to: ..\img\posts
---

## 一.准备工作

### 同步时间

````
yum install ntpdate
ntpdate cn.pool.ntp.org
````

### 设置主机名

```
vi /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=node-01
```

### 配置 IP 、主机名

```
vi /etc/hosts
```

### 配置  ssh 免密登陆

生成 ssh 免登陆密钥

````
ssh-keygen -t rsa （四个回车
````

执行完这个命令后，会生成 id_rsa（私钥）、id_rsa.pub（公钥）
将公钥拷贝到要包括自己在内的所有主机上

```
ssh-copy-id 主机名
```

### 配置防火墙

```
#查看防火墙状态
service iptables status
#关闭防火墙
service iptables stop
#查看防火墙开机启动状态
chkconfig iptables --list
#关闭防火墙开机启动
chkconfig iptables off
```

 ###  JDK 环境安装

````
java -version 
````

输入后可以正常使用即可

### 整体架构

| 节点名\相关节点 |          |          |                   |                 |             |
| --------------- | :------: | -------- | ----------------- | --------------- | ----------- |
| node-1          | namenode | datanode |                   | ResourceManager | NodeManager |
| node-2          |          | datanode | SecondaryNameNode |                 | NodeManager |
| node-3          |          | datanode |                   |                 | NodeManager |



## 二.hadoop配置文件修改

解压 hadoop-2.7.4-with-centos-6.7.tar.gz，目录结构如下：

```
bin：Hadoop 最基本的管理脚本和使用脚本的目录，这些脚本是 sbin 目录下管理脚本的基础实现，用户可以直接		使用这些脚本管理和使用 Hadoop。

etc：Hadoop 配置文件所在的目录，包括 core-site,xml、hdfs-site.xml、mapred-site.xml 等从 Hadoop1.0 		继承而来的配置文件和 yarn-site.xml 等Hadoop2.0 新增的配置文件。

include：对外提供的编程库头文件（具体动态库和静态库在 lib 目录中），这些头文件均是用 C++定义的，通常用于 C++程序访问 HDFS 或者编写 MapReduce程序。

lib：该目录包含了 Hadoop 对外提供的编程动态库和静态库，与 include 目录中的头文件结合使用。

libexec：各个服务对用的 shell 配置文件所在的目录，可用于配置日志输出、启动参数（比如 JVM 参数）等基本信	息。

sbin：Hadoop 管理脚本所在的目录，主要包含 HDFS 和 YARN 中各类服务的启动/关闭脚本。

share：Hadoop 各个模块编译后的 jar 包所在的目录

```

### 注意事项:

Hadoop 安装主要就是配置文件的修改，一般在主节点进行修改，完毕后 scp下发给其他各个从节点机器。

配置文件的位置:

```
hadoop-2.7.4/etc/hadoop/
```



### hadoop-env.sh

​	文件中设置的是 Hadoop 运行时需要的环境变量。JAVA_HOME是必须设置的，即使我们当前的系统中设置了 JAVA_HOME，它也是不认识的，因为 Hadoop 即使是在本机上执行，它也是把当前的执行环境当成远程服务器。

```
vi hadoop-env.sh
export JAVA_HOME=/root/apps/jdk1.8.0_65
```

### core-site.xml

​	hadoop 的核心配置文件，有默认的配置项 core-default.xml。core-default.xml 与 core-site.xml 的功能是一样的，如果在 core-site.xml 里没有配置的属性，则会自动会获取 core-default.xml 里的相同属性的值。

````
<!-- 用于设置 Hadoop 的文件系统，由 URI 指定 -->
<property>
<name>fs.defaultFS</name>
<value>hdfs://node-1:9000</value>
</property>

<!-- 配置 Hadoop 的临时目录,默认/tmp/hadoop-${user.name} -->
<property>
<name>hadoop.tmp.dir</name>
<value>/home/hadoop/hadoop-2.4.1/tmp</value>
</property>
````

### hdfs-site.xml

​	HDFS 的核心配置文件，有默认的配置项 hdfs-default.xml。hdfs-default.xml 与 hdfs-site.xml 的功能是一样的，如果在 hdfs-site.xml 里没有配置的属性，则会自动会获取 hdfs-default.xml 里的相同属性的值。

​	副本数目指的是需要备份的数目,但是要注意的但是,它已经包含本体,所以2即为备份一份

```
<!-- 指定 HDFS 副本的数量 -->
<property>
<name>dfs.replication</name>
<value>2</value>
</property>
<!-- secondary namenode 所在主机的 ip 和端口->
<property>
<name>dfs.namenode.secondary.http-address</name>
<value>192.168.1.152:50090</value>
</property>
```

###  mapred-site.xml

​	MapReduce 的核心配置文件，有默认的配置项 mapred-default.xml。
​	mapred-default.xml 与 mapred-site.xml 的功能是一样的，如果在 mapred-site.xml 里没有配置的属性，则会自动会获取 mapred-default.xml 里的相同属性的值。

​	该配置文件在目录中表现的是mapred-site.xml.template,所以需要复制一个重命名为

````
<!-- 指定 mr 运行时框架，这里指定在 yarn 上，默认是 local -->
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>
````



### yarn-site.xml

​	YARN 的核心配置文件，有默认的配置项 yarn-default.xml。yarn-default.xml 与 yarn-site.xml 的功能是一样的，如果在 yarn-site.xml 里没有配置的属性，则会自动会获取 yarn-default.xml 里的相同属性的值。

```
<!-- 指定 YARN 的老大（ResourceManager）的地址 -->
<property>
<name>yarn.resourcemanager.hostname</name>
<value>node-1</value>
</property>
<!-- NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce
程序默认值："" -->
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>
```

### slaves

slaves 文件里面记录的是集群主机名。一般有以下两种作用：
一是：配合一键启动脚本如 start-dfs.sh、stop-yarn.sh 用来进行集群启动。这时候 slaves 文件里面的主机标记的就是从节点角色所在的机器。
二是：可以配合 hdfs-site.xml 里面 dfs.hosts 属性形成一种白名单机制。dfs.hosts 指定一个文件，其中包含允许连接到 NameNode 的主机列表。必须指定文件的完整路径名。如果值为空，则允许所有主机。例如：

```
<property>
<name> dfs.hosts </name>
<value>/root/apps/hadoop/etc/hadoop/slaves </value>
</property>
```

而我们需要做的事

把localhost删掉

写入我们的主机地址

### Hadoop 环境变量

编辑环境变量的配置文件：

```
vi /etc/profile
export JAVA_HOME= /root/apps/jdk
export HADOOP_HOME= /root/apps/hadoop-2.7.4
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

保存配置文件，刷新配置文件：

```
source /etc/profile
```

## 三.hadoop启动

### 格式化操作

要启动 Hadoop 集群，需要启动 HDFS 和 YARN 两个集群。
注意： 首次启动 S HDFS 时，必须对其进行格式化 操作。本质上是一些清理和准备工作，因为此时的 HDFS 在物理上还是不存在的。
hdfs namenode–format 或者 hadoop namenode –format

### 1.单节点逐个启动

在主节点上使用以下命令启动 HDFS NameNode：
hadoop-daemon.sh start namenode
在每个从节点上使用以下命令启动 HDFS DataNode：
hadoop-daemon.sh start datanode
在主节点上使用以下命令启动 YARN ResourceManager：
yarn-daemon.sh start resourcemanager
在每个从节点上使用以下命令启动 YARN nodemanager：
yarn-daemon.sh start nodemanager
以上脚本位于$HADOOP_PREFIX/sbin/目录下。如果想要停止某个节点上某个角色，只需要把命令中的 start 改为 stop 即可。

### 2.脚本一键启动

如果配置了 etc/hadoop/slaves 和 ssh 免密登录，则可以使用程序脚本启动
所有 Hadoop 两个集群的相关进程，在主节点所设定的机器上执行。
hdfs：$HADOOP_PREFIX/sbin/start-dfs.sh
yarn: $HADOOP_PREFIX/sbin/start-yarn.sh
停止集群：stop-dfs.sh、stop-yarn.sh

## 四.查看页面

NameNode http://host:50070/ 默认 50070.
ResourceManager http://host:8088/ 默认 8088.

![1520173116229](/img/posts/1520173116229.png)

![1520173197302](/img/posts/1520173197302.png)

没问题就ok了!