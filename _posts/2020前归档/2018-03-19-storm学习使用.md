---
layout:     post
title:      storm的学习使用
date:       2018-1-19
author:     yunzhs
header-img: img/Fate of Princess.jpg
catalog: true
tags:
    - storm
typora-root-url: ..
typora-copy-images-to: ..\img\posts
---

## 1.storm是什么?

### 1.1storm的介绍

​	storm是twitter公司开源贡献给apache的一款实时流式处理的一个开源软件，主要用于解决数据的实时计算

以及实时的处理等方面的问题

### 1.2storm的特点

​	Storm是一个开源的分布式实时计算系统，可以简单、可靠的处理大量的数据流。Storm有很多使用场景：如

实时分析，在线机器学习，持续计算，分布式RPC，ETL等等。Storm支持水平扩展，具有**高容错性**，**保证每个消**

**息都会得到处理**，而且**处理速度很快**（在一个小集群中，每个结点每秒可以处理数以百万计的消息）。Storm的部

署和运维都很便捷，而且更为重要的是可以使用任意编程语言来开发应用。

- 编程模型简单

在大数据处理方面hadoop已经耳熟能详，基于Google Map/Reduce来实现的Hadoop为开发者提供了map、reduce原语，使并行批处理程序变得非常地简单和优美。同样，Storm也为大数据的实时计算提供了一些简单优美的原语，这大大降低了开发并行实时处理的任务的复杂性，帮助你快速、高效的开发应用。

- 可扩展

在Storm集群中真正运行topology的主要有三个实体：工作进程、线程和任务。Storm集群中的每台机器上都可以运行多个工作进程，每个工作进程又可创建多个线程，每个线程可以执行多个任务，任务是真正进行数据处理的实体，我们开发的spout、bolt就是作为一个或者多个任务的方式执行的。

因此，计算任务在多个线程、进程和服务器之间并行进行，支持灵活的水平扩展。

- 高可靠性
- 容错性
- 支持多种编程语言
- 支持本地模式
- 高效

## 2.storm的架构模型

![52145092956](/img/posts/1521450929562.png)

1.Nimbus：负责资源分配和任务调度。新版本中的nimbus节点可以有多个，做主备

2.Supervisor：负责接受nimbus分配的任务，启动和停止属于自己管理的worker进程。

3.Worker：运行具体处理组件逻辑的进程。

4.Task：worker中每一个spout/bolt的线程称为一个task. 在storm0.8之后，task不再与物理线程对应，同一个

spout/bolt的task可能会共享一个物理线程，该线程称为executor。最新版本的Jstorm已经废除了task的概念

## 3.storm与hadoop的对比

![52145108034](/img/posts/1521451080341.png)

## 4.storm的安装

三台机器运行服务规划

| 运行服务\机器规划 | Node01             | Node02          | Node03          |
| ----------------- | ------------------ | --------------- | --------------- |
| Zookeeper版本     | 3.4.9              |                 |                 |
| Zookeeper服务     | 是                 | 是              | 是              |
| Storm版本         | Apache-storm-1.1.1 |                 |                 |
| Nimbus服务        | 是（leader）       | 是              | 是              |
| Supervisor服务    | 是                 | 是              | 是              |
| IP地址规划        | 192.168.217.228    | 192.168.217.229 | 192.168.217.230 |

### 4.1zookeeper的安装

安装过程略

### 4.2三台机器安装storm集群

1、上传storm压缩包

2、解压

3、修改配置文件

```
storm.zookeeper.servers:
     - "node-01"
     - "node-02"
     - "node-03"
# 
nimbus.seeds: ["node-01", "node-02", "node-03"]

storm.local.dir: "/export/servers/apache-storm-1.1.1/stormdata" 
ui.port: 8088
supervisor.slots.ports:
    - 6700
    - 6701
    - 6702
    - 6703
```

4、将storm安装程序分发拷贝到另外两台机器上

scp -r apache-storm-1.1.1/ node-02:/export/servers/

scp -r apache-storm-1.1.1/ node-03:/export/servers/

5、三台机器启动storm服务

Node01 启动相关服务
启动 nimbus进程
nohup bin/storm nimbus >/dev/null 2>&1 &
启动web  UI
nohup bin/storm ui >/dev/null 2>&1 &
启动logViewer
nohup bin/storm logviewer >/dev/null 2>&1 & 
启动supervisor
nohup bin/storm supervisor >/dev/null 2>&1 &

Node02启动相关服务
nimbus：nohup bin/storm nimbus >/dev/null 2>&1 & 
logviewer：nohup bin/storm logviewer >/dev/null 2>&1 & 
supervisor：nohup bin/storm supervisor >/dev/null 2>&1 &

node03启动相关服务
nimbus：nohup bin/storm nimbus >/dev/null 2>&1 & 
logviewer：nohup bin/storm logviewer >/dev/null 2>&1 & 
supervisor：nohup bin/storm supervisor >/dev/null 2>&1 &

## 6.storm的UI界面管理

访问地址:

http://node-01:8088/index.html

## 7.storm的编程模型

![52145157083](/img/posts/1521451570832.png)

DataSource：外部数据源

Spout：接受外部数据源的组件，将外部数据源转化成Storm内部的数据，以Tuple为基本的传输单元下发给Bolt

Bolt:接受Spout发送的数据，或上游的bolt的发送的数据。根据业务逻辑进行处理。发送给下一个Bolt或者是存储到某种介质上。介质可以是mongodb或mysql，或者其他。

Tuple：Storm内部中数据传输的基本单元，里面封装了一个List对象，用来保存数据。

StreamGrouping:数据分组策略 
7种：shuffleGrouping(Random函数),

Non Grouping(Random函数),

FieldGrouping(Hash取模)、

Local or ShuffleGrouping 本地或随机，优先本地。

其中Local or ShuffleGrouping 是如果分组的时候接收bolt的线程和发送者在一个JVM中默认优先选择一个JVM中的bolt就是local，否则和ShuffleGrouping效果一样。

## 8.storm的入门程序

### 8.1实现单次计数的统计

第一步：创建maven  java 项目，导入jar包

```
<dependencies>
		 <dependency>
		    <groupId>org.apache.storm</groupId>
		    <artifactId>storm-core</artifactId>
		    <version>1.1.1</version>
		    <scope>provided</scope>
		</dependency>
		<dependency>
            <groupId>org.clojure</groupId>
            <artifactId>clojure</artifactId>
            <version>1.9.0</version>
         </dependency>
  </dependencies>
  
   <build>  
    <plugins>  
        <plugin>  
            <groupId>org.apache.maven.plugins</groupId>  
            <artifactId>maven-compiler-plugin</artifactId>  
            <configuration>  
                <source>1.8</source>
                <target>1.8</target>  
            </configuration>  
        </plugin>  
    </plugins>  
</build>
```

第二步：开发我们的spout，随机选择一些单词发送到下一个bolt

```
/*
RandomSpout继承BaseRichSpout表示我们的RandomSpout是一个规范的spout数据源
 */
public class RandomSpout extends BaseRichSpout {

    private  String[]  arrays ;
    private SpoutOutputCollector collector;
    private Random random;

    /**
     * 初始化的方法，只会被执行一次，所有关于初始化的配置都可以放在这里面来做
     * @param conf
     * @param context
     * @param collector
     */
    @Override
    public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {
        random = new Random();
        this.collector = collector;
       arrays = new String[]{"hadoop hive","hive flume","haodop sqoop","hive flume","kafka hadoop","kafka storm"};
    }

    /**
     * nextTuple   这个方法会被反复不断地调用，只要有了数据，就会被调用
     */
    @Override
    public void nextTuple() {
        try {
            //通过collector调用emit方法来进行数据的方法
            String words =  arrays[random.nextInt(arrays.length)];
            collector.emit(new Values(words));
            Thread.sleep(1000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

    /**
     * 发送出去的一条条数给定义一个字段，map  key  value
     * @param declarer
     */
    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {
        declarer.declare(new Fields("words"));
    }

```

第三步：开发我们的SplitBolt将我们的英文句子切割成一个个的单词

```
public class SplitBolt extends BaseBasicBolt{


    /**
     * execute  表示我们被执行的方法，每一条数据过来都会调用这个execut方法
     * @param input
     * @param collector
     * tuple  就是我们的一条条的数据从上游发送过来的
     * BasicOutputCollector  通过调用emit方法来实现我们的数据往下游发送
     */
    @Override
    public void execute(Tuple input, BasicOutputCollector collector) {
        String words = input.getStringByField("words");
        //将我们上游发送的数据切割开来，变成一个个的单词
        String[] split = words.split(" ");  //  hadoop 1   hive  1
        for (String str : split) {
            collector.emit(new Values(str,1));
        }



    }
    /**
     * 发送出去的一条条数给定义一个字段，map  key  value
     * @param declarer
     */
    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {
        declarer.declare(new Fields("word","num"));
    }
}
```

第四步：开发我们的计数器CountBolt

```
/**
 * 我们的单词计数
 */
public class CountBolt extends BaseBasicBolt{


    private Map<String,Integer> map;

    /*
   覆写我们的prepare方法，用于我们的初始化
     */
    @Override
    public void prepare(Map stormConf, TopologyContext context) {
        map = new HashMap<String, Integer>();
    }

    @Override
    public void execute(Tuple input, BasicOutputCollector collector) {
        String word = input.getStringByField("word");
        Integer num = input.getIntegerByField("num");
        if(map.containsKey(word)){
            map.put(word,map.get(word)+num);

        }else{
            map.put(word,num);
        }
        System.out.println(map.toString());

    }

    //如果下游没有bolt，数据就不用往下发送了，也不用管这个方法了
    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {

    }
}
```

第五步：组装我们的程序向storm集群进行提交

```
public static void main(String[] args) throws InvalidTopologyException, AuthorizationException, AlreadyAliveException {
        TopologyBuilder builder = new TopologyBuilder();
        //设置我们topology的spout
        //这里还可以变成三个参数的，最后一个参数指定我们程序运行的线程数量
        builder.setSpout("randomSpout",new RandomSpout(),1);
        //通过shuffleGrouping这个方法，将我们的spout与bolt之间的前后顺序关系给指定好
        //localOrShuffleGrouping  优先处理本地的数据，本地的数据不需要网络的拷贝，速度会更加快，如果本地没有数据了，再通过网络拷贝去其他节点上拉取数据来进行处理
        builder.setBolt("splitBolt",new SplitBolt(),3).globalGrouping("randomSpout");//.shuffleGrouping("randomSpout");//fieldsGrouping("randomSpout",new Fields("words"))//
        builder.setBolt("countBolt",new CountBolt(),3).globalGrouping("splitBolt");
        //提交topology的时候一些配置信息
        Config config = new Config();
        if(args.length > 0){
            config.setNumWorkers(3);
            //关闭日志信息，提交到集群上面去不需要大量的日志出来
            config.setDebug(false);
            //集群模式运行
            StormSubmitter submitter = new StormSubmitter();
            //通过topologyBuilder来创建我们的topology
            StormTopology topology = builder.createTopology();
            submitter.submitTopology(args[0],config,topology);
        }else{
            //打开调试模式，我们本地运行可以看到更多的日志信息
            config.setDebug(true);
            //本地模式运行
            LocalCluster cluster = new LocalCluster();
            cluster.submitTopology("localStrom",config,builder.createTopology());
        }
    }

```

## 9.storm的分发策略

Storm当中的分组策略，一共有八种：

所谓的grouping策略就是在Spout与Bolt、Bolt与Bolt之间传递Tuple的方式。总共有八种方式：

 1）shuffleGrouping（随机分组）随机分组；将tuple随机分配到bolt中，能够保证各task中处理的数据均衡；

 2）fieldsGrouping（按照字段分组，在这里即是同一个单词只能发送给一个Bolt）

按字段分组； 根据设定的字段相同值得tuple被分配到同一个bolt进行处理；

举例：builder.setBolt("mybolt",new MyStoreBolt(),5).fieldsGrouping("checkBolt",newFields("uid"));

说明：该bolt由5个任务task执行，相同uid的元组tuple被分配到同一个task进行处理；该task接收的元祖字段是mybolt发射出的字段信息，不受uid分组的影响。

​    该分组不仅方便统计而且还可以通过该方式保证相同uid的数据保存不重复（uid信息写入数据库中唯一）；

 3）allGrouping（广播发送，即每一个Tuple，每一个Bolt都会收到）广播发送：所有bolt都可以收到该tuple

 4）globalGrouping（全局分组，将Tuple分配到task id值最低的task里面）全局分组：tuple被发送给bolt的同一个并且最小task_id的任务处理，实现事务性的topology  保证全局有序，全局找task_id最小的那个线程，所有的数据都由最小的这个task_id来进行处理，保证数据的顺序

 5）noneGrouping（随机分派）不分组：效果等同于shuffleGrouping.

 6）directGrouping（直接分组，指定Tuple与Bolt的对应发送关系）

直接分组：由tuple的发射单元直接决定tuple将发射给那个bolt，一般情况下是由接收tuple的bolt决定接收哪个bolt发射的Tuple。这是一种比较特别的分组方法，用这种分组意味着消息的发送者指定由消息接收者的哪个task处理这个消息。 只有被声明为Direct Stream的消息流可以声明这种分组方法。而且这种消息tuple必须使用emitDirect方法来发射。消息处理者可以通过TopologyContext来获取处理它的消息的taskid(OutputCollector.emit方法也会返回taskid)。

 7）Local or shuffle Grouping本地或者随机分组，优先将数据发送到本机的处理器executor，如果本机没有对应的处理器，那么再发送给其他机器的executor，避免了网络资源的拷贝，减轻网络传输的压力

 8）customGrouping （自定义的Grouping）

## 10.storm的并行度

并行度，说白了就是设置我们的storm程序的多进程与多线程的过程

```
可以通过config.setNumWorkers(3);
```

来设置我们的进程数量

可以通过

```
builder.setSpout("randomSpout",new RandomSpout(),3);
```

最后这个参数来设置我们的线程的并行度，提高我们程序的运行速度

## 11.storm与kafka的整合

第一步：导入jar包

```
<dependencies>
    <dependency>
        <groupId>org.apache.storm</groupId>
        <artifactId>storm-core</artifactId>
        <version>1.1.1</version>
        <!--  运行的时候，如果指定这个scope为provided，那么运行的时候就会找不到这个jar包里面的任何类，所以运行的时候要把这个关闭，打包时候再把这个打开 -->
       <!-- <scope>provided</scope>-->
        <!--  provided表示我们开发的时候需要，打包的时候不需要 -->
    </dependency>

    <!--  use new kafka spout code -->
    <dependency>
        <groupId>org.apache.storm</groupId>
        <artifactId>storm-kafka-client</artifactId>
        <version>1.1.1</version>
    </dependency>
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka-clients</artifactId>
        <version>0.10.0.0</version>
    </dependency>
</dependencies>

```

第二步：创建我们程序的入口main函数

```
public static void main(String[] args) throws InvalidTopologyException, AuthorizationException, AlreadyAliveException {
    /*  1.1.2版本的storm与kafka的整合
  BrokerHosts hosts = new ZkHosts(zkConnString);
    SpoutConfig spoutConfig = new SpoutConfig(hosts, topicName, "/" + topicName, UUID.randomUUID().toString());
    spoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());
    KafkaSpout kafkaSpout = new KafkaSpout(spoutConfig);*/

    TopologyBuilder builder = new TopologyBuilder();
    //创建一个kafkaSpout用于我们从kafka当中读取数据
    KafkaSpoutConfig.Builder<String, String> kafkaSpoutBuilder = KafkaSpoutConfig.builder("node-01:9092,node-02:9092,node-03:9092", "test");
    kafkaSpoutBuilder.setGroupId("hello");
    //有一个值可以设置从我们上次哪一个地方进行消费
    kafkaSpoutBuilder.setFirstPollOffsetStrategy(KafkaSpoutConfig.FirstPollOffsetStrategy.LATEST);
    KafkaSpoutConfig<String, String> kafkaSpoutConfig = kafkaSpoutBuilder.build();
    KafkaSpout<String, String> kafkaSpout = new KafkaSpout<>(kafkaSpoutConfig);//需要一个参数叫做kafkaSpoutConfig
    builder.setSpout("kafaSpout",kafkaSpout);
    builder.setBolt("myKafkaBolt",new MyKafkaBolt()).localOrShuffleGrouping("kafaSpout");
    Config config = new Config();
    if(args.length > 0){
        config.setDebug(false);
        StormSubmitter submitter = new StormSubmitter();
        submitter.submitTopology(args[0],config,builder.createTopology());
    }else{
        config.setDebug(true);
        LocalCluster cluster = new LocalCluster();
        cluster.submitTopology("stormandkafka",config,builder.createTopology());
    }
}
```

第三步：创建我们程序的bolt

```
/**
 * 继承BaseBasicBolt  表名我们的MyKafkaBolt是一个规范的bolt实现
 */
public class MyKafkaBolt extends BaseBasicBolt{

    @Override
    public void execute(Tuple input, BasicOutputCollector collector) {
        List<Object> values = input.getValues();
       /* for (Object value : values) {
            System.out.println(value);
        }*/
        Object value = input.getValue(4);
      //  System.out.println(value);
        System.out.println("我要准备打印了");
        System.out.println(value.toString()+"是我接收到的值");
    }

    @Override
    public void declareOutputFields(OutputFieldsDeclarer declarer) {

    }
}

```

为什么要取getValue(4)?

![52154756872](/img/posts/1521547568722.png)

## 12.实时看板案例

### 12.1项目需求梳理

根据订单mq，快速计算双11当天的订单量、销售金额。

![52154902301](/img/posts/1521549023012.png)

### 12.2项目架构模型

支付系统+kafka+storm/Jstorm集群+redis集群

1、支付系统发送mq到kafka集群中，编写storm程序消费kafka的数据并计算实时的订单数量、订单数量

2、将计算的实时结果保存在redis中

3、外部程序访问redis的数据实时展示结果

![52154906928](/img/posts/1521549069284.png)



